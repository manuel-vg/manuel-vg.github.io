---
title: "Testing the limits of logical reasoning in neural and hybrid models"
collection: publications
category: conferences
permalink: /publication/2024-06-16-testing-the-limits-of-logical-reasoning-in-neural-and-hybrid-models
excerpt: 'We evaluate how well neural models generalize syllogistic logical reasoning, using custom tests focused on compositionality and recursion.'
date: 2024-06-16
venue: 'Annual Conference of the North American Chapter of the Association for Computational Linguistics'
paperurl: 'https://aclanthology.org/2024.findings-naacl.147.pdf'
citation: 'Vargas Guzmán et al. (2024). &quot;Testing the limits of logical reasoning in neural and hybrid models.&quot; <i>Findings of the Association for Computational Linguistics: NAACL</i>. 2267–2279.'
---

We study the ability of neural and hybrid models to generalize logical reasoning patterns. We created a series of tests for analyzing various aspects of generalization in the context of language and reasoning, focusing on compositionality and recursiveness. We used them to study the syllogistic logic in hybrid models, where the network assists in premise selection. We analyzed feed-forward, recurrent, convolutional, and transformer architectures. Our experiments demonstrate that even though the models can capture elementary aspects of the meaning of logical terms, they learn to generalize logical reasoning only to a limited degree.
